{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import operator\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pymystem3 import Mystem\n",
    "from tqdm import tqdm\n",
    "from joblib import dump, load\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import word2vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import pickle\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeFeatureVec(words,model,num_features):\n",
    "    featureVec = np.zeros((num_features,), dtype='float32')\n",
    "    n = 0\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    \n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            n+=1\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    featureVec = np.divide(featureVec,n)\n",
    "    return featureVec\n",
    "\n",
    "def getAverageVec(posts, model,num_features):\n",
    "    cnt = 0\n",
    "    reviewFeatureVecs = np.zeros((len(posts), num_features), dtype='float32')\n",
    "    \n",
    "    for sentence in posts:\n",
    "        reviewFeatureVecs[cnt] = makeFeatureVec(sentence,model,num_features)\n",
    "        cnt+=1\n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Когда-то я был добрым романтиком, который стре...</td>\n",
       "      <td>1</td>\n",
       "      <td>['добрый', 'романтик', 'стремиться', 'помогать...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Здраствуйте! Я каждый день просыпаюсь с мыслью...</td>\n",
       "      <td>1</td>\n",
       "      <td>['здраствовать', 'каждый', 'просыпаться', 'мыс...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  Когда-то я был добрым романтиком, который стре...      1   \n",
       "1  Здраствуйте! Я каждый день просыпаюсь с мыслью...      1   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  ['добрый', 'романтик', 'стремиться', 'помогать...  \n",
       "1  ['здраствовать', 'каждый', 'просыпаться', 'мыс...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83790, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates('text', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81632, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.cleaned_text, df.label, \n",
    "                                                    test_size = 0.2, random_state = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfVectorizer(max_features=5000, min_df=10)\n",
    "X_train_tfidf_model = tfidf_transformer.fit(X_train)\n",
    "X_train_tfidf_vector = X_train_tfidf_model.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(X_train_tfidf_model, 'tfidf.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_tfidf_vector = X_train_tfidf_model.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"train_tfiidf.pkl\", \"wb\") as f:\n",
    "    pickle.dump(X_train_tfidf_vector,f)\n",
    "    \n",
    "with open(\"train_label.pkl\", \"wb\") as f:\n",
    "    pickle.dump(y_train,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"test_tfiidf.pkl\", \"wb\") as f:\n",
    "    pickle.dump(X_test_tfidf_vector,f)\n",
    "    \n",
    "with open(\"test_label.pkl\", \"wb\") as f:\n",
    "    pickle.dump(y_test,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = 120\n",
    "min_word_count = 40\n",
    "num_workers = 4\n",
    "context = 10\n",
    "downsampling = 1e-3\n",
    "\n",
    "model = word2vec.Word2Vec(X_train,workers=num_workers, size=num_features,\\\n",
    "                          min_count = min_word_count,window=context, sample=downsampling)\n",
    "model.init_sims(replace = True)\n",
    "model_name = \"word2vec\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataVecs_train = getAverageVec(X_train,model,num_features)\n",
    "np.isnan(DataVecs_train).any()\n",
    "np.count_nonzero(np.isnan(DataVecs_train))\n",
    "DataVecs_train = np.nan_to_num(DataVecs_train)\n",
    "np.isnan(DataVecs_train).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataVecs_test = getAverageVec(X_test,model,num_features)\n",
    "np.isnan(DataVecs_test).any()\n",
    "np.count_nonzero(np.isnan(DataVecs_test))\n",
    "DataVecs_test = np.nan_to_num(DataVecs_test)\n",
    "np.isnan(DataVecs_test).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"train_word2vec.pkl\", \"wb\") as f:\n",
    "    pickle.dump(DataVecs_train,f)\n",
    "    \n",
    "with open(\"test_word2vec.pkl\", \"wb\") as f:\n",
    "    pickle.dump(DataVecs_test,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
